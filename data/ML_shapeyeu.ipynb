{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oxboJW9Ads7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fea83dd-4459-4109-93d9-af469c42b0ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'First-ML-Project'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 75 (delta 16), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (75/75), 170.49 KiB | 2.75 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "/content/First-ML-Project\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!git clone https://github.com/sv3t1k/First-ML-Project.git\n",
        "%cd First-ML-Project\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r data/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2ydNZmPwWyj",
        "outputId": "9b4142c5-14ab-4ad8-938b-bad37eee3109"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r data/requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r data/requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r data/requirements.txt (line 3)) (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r data/requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r data/requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from -r data/requirements.txt (line 6)) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->-r data/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r data/requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r data/requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r data/requirements.txt (line 1)) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r data/requirements.txt (line 2)) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r data/requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r data/requirements.txt (line 3)) (8.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r data/requirements.txt (line 3)) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->-r data/requirements.txt (line 3)) (4.67.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r data/requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r data/requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r data/requirements.txt (line 4)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r data/requirements.txt (line 4)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r data/requirements.txt (line 4)) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r data/requirements.txt (line 4)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r data/requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r data/requirements.txt (line 1)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cqKv-vjycnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from data.src.loader import DataLoader\n",
        "from data.src.preprocessor import TextPreprocessor\n",
        "from data.src.models import ModelTrainer\n",
        "\n",
        "print(\"--- STEP 1: Data Loading ---\")\n",
        "loader = DataLoader(\"data/train.csv\")\n",
        "df = loader.load_and_clean()\n",
        "\n",
        "print(f\"Number of rows loaded: {len(df)}\")\n",
        "print(\"\\nClass Distribution (Point 4):\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "print(\"\\n--- STEP 2: Text Cleaning (Preprocessing) ---\")\n",
        "preprocessor = TextPreprocessor()\n",
        "\n",
        "df['cleaned_text'] = df['reviews.text'].astype(str).apply(preprocessor.clean_text)\n",
        "\n",
        "print(\"Example before:\", df['reviews.text'].iloc[0][:100], \"...\")\n",
        "print(\"Example after:\", df['cleaned_text'].iloc[0][:100], \"...\")\n",
        "\n",
        "print(\"\\n--- STEP 3: Vectorization (TF-IDF) ---\")\n",
        "trainer = ModelTrainer()\n",
        "X = trainer.vectorize_data(df['cleaned_text'])\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "trainer.compare_models(X_train, X_test, y_train, y_test)\n",
        "\n",
        "final_model = trainer.fine_tune_logistic(X_train, y_train)\n",
        "\n",
        "print(\"\\n--- STEP 5: Final Metrics ---\")\n",
        "predictions = final_model.predict(X_test)\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9dBAyBywsJu",
        "outputId": "f23171a2-1b7c-47c0-f24b-0764246d263c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STEP 1: Data Loading ---\n",
            "Number of rows loaded: 1664\n",
            "\n",
            "Class Distribution (Point 4):\n",
            "label\n",
            "1    1587\n",
            "0      77\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- STEP 2: Text Cleaning (Preprocessing) ---\n",
            "Example before: This product so far has not disappointed. My children love to use it and I like the ability to monit ...\n",
            "Example after: product far disappointed child love use like ability monitor control content see ease ...\n",
            "\n",
            "--- STEP 3: Vectorization (TF-IDF) ---\n",
            "\n",
            "--- Model Comparison ---\n",
            "Naive Bayes Accuracy: 0.9550\n",
            "Logistic Regression Accuracy: 0.9550\n",
            "\n",
            "--- The final model is trained with class balance ---\n",
            "\n",
            "--- STEP 5: Final Metrics ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.20      0.26        15\n",
            "           1       0.96      0.98      0.97       318\n",
            "\n",
            "    accuracy                           0.95       333\n",
            "   macro avg       0.67      0.59      0.62       333\n",
            "weighted avg       0.94      0.95      0.94       333\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def analyze_web_page(url, model, vectorizer, preprocessor):\n",
        "    print(f\"\\n--- Analyzing page: {url} ---\")\n",
        "\n",
        "\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    web_texts = [p.get_text() for p in soup.find_all('p') if len(p.get_text()) > 20]\n",
        "\n",
        "    if not web_texts:\n",
        "        print(\"Text for analysis not found.\")\n",
        "        return\n",
        "\n",
        "    cleaned_web_texts = [preprocessor.clean_text(t) for t in web_texts]\n",
        "    web_vectors = vectorizer.transform(cleaned_web_texts)\n",
        "\n",
        "    predictions = model.predict(web_vectors)\n",
        "    probabilities = model.predict_proba(web_vectors)\n",
        "\n",
        "\n",
        "    for i in range(min(5, len(web_texts))):\n",
        "        sentiment = \"POSITIVE\" if predictions[i] == 1 else \"NEGATIVE\"\n",
        "        conf = probabilities[i][predictions[i]] * 100\n",
        "        print(f\"\\nText: {web_texts[i][:100]}...\")\n",
        "        print(f\"Result: {sentiment} ({conf:.2f}% confidence)\")\n",
        "\n",
        "test_url = \"https://www.gsmarena.com/vivo_iqoo_15_ultra_5g-reviews-14445.php\"\n",
        "analyze_web_page(test_url, final_model, trainer.vectorizer, preprocessor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MVrtH6-1M9H",
        "outputId": "ad8c4bd8-917d-461a-a993-badd00f3c080"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Analyzing page: https://www.gsmarena.com/vivo_iqoo_15_ultra_5g-reviews-14445.php ---\n",
            "\n",
            "Text: Sohail , 30 Jan 2026HzRegarding the display refresh rate, Iâ€™m seeing conflicting rumors. Some early ...\n",
            "Result: POSITIVE (69.69% confidence)\n",
            "\n",
            "Text: Md. Faim Roze , 15 hours agoMissing 120fps video record option So SadYou are at the mercy of the sen...\n",
            "Result: POSITIVE (72.23% confidence)\n",
            "\n",
            "Text: Missing 120fps video record option So Sad...\n",
            "Result: POSITIVE (69.95% confidence)\n",
            "\n",
            "Text: As it is known for gaming phone, but with this model, the brand could for an example, implemented ne...\n",
            "Result: POSITIVE (70.93% confidence)\n",
            "\n",
            "Text: Amitangshu, 05 Feb 2026It has LTPO. The vailla Iqoo 15 has a LTPO panelCorrect. And the iQOO 15 Ultr...\n",
            "Result: POSITIVE (64.57% confidence)\n"
          ]
        }
      ]
    }
  ]
}
